; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx900 -verify-machineinstrs < %s | FileCheck %s

declare hidden void @void_func_i32_inreg(i32 inreg)

define void @tail_call_i32_inreg_divergent(i32 %vgpr) {
; CHECK-LABEL: tail_call_i32_inreg_divergent:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_mov_b32 s16, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_or_saveexec_b64 s[18:19], -1
; CHECK-NEXT:    buffer_store_dword v40, off, s[0:3], s33 ; 4-byte Folded Spill
; CHECK-NEXT:    s_mov_b64 exec, s[18:19]
; CHECK-NEXT:    v_writelane_b32 v40, s16, 18
; CHECK-NEXT:    v_writelane_b32 v40, s30, 0
; CHECK-NEXT:    v_writelane_b32 v40, s31, 1
; CHECK-NEXT:    v_writelane_b32 v40, s34, 2
; CHECK-NEXT:    v_writelane_b32 v40, s35, 3
; CHECK-NEXT:    v_writelane_b32 v40, s36, 4
; CHECK-NEXT:    v_writelane_b32 v40, s37, 5
; CHECK-NEXT:    v_writelane_b32 v40, s38, 6
; CHECK-NEXT:    v_writelane_b32 v40, s39, 7
; CHECK-NEXT:    v_writelane_b32 v40, s48, 8
; CHECK-NEXT:    v_writelane_b32 v40, s49, 9
; CHECK-NEXT:    v_writelane_b32 v40, s50, 10
; CHECK-NEXT:    v_writelane_b32 v40, s51, 11
; CHECK-NEXT:    v_writelane_b32 v40, s52, 12
; CHECK-NEXT:    v_writelane_b32 v40, s53, 13
; CHECK-NEXT:    v_writelane_b32 v40, s54, 14
; CHECK-NEXT:    v_writelane_b32 v40, s55, 15
; CHECK-NEXT:    v_writelane_b32 v40, s64, 16
; CHECK-NEXT:    s_mov_b32 s50, s15
; CHECK-NEXT:    s_mov_b32 s51, s14
; CHECK-NEXT:    s_mov_b32 s52, s13
; CHECK-NEXT:    s_mov_b32 s53, s12
; CHECK-NEXT:    s_mov_b64 s[34:35], s[10:11]
; CHECK-NEXT:    s_mov_b64 s[36:37], s[8:9]
; CHECK-NEXT:    s_mov_b64 s[38:39], s[6:7]
; CHECK-NEXT:    s_mov_b64 s[48:49], s[4:5]
; CHECK-NEXT:    s_mov_b64 s[54:55], exec
; CHECK-NEXT:    s_addk_i32 s32, 0x400
; CHECK-NEXT:    v_writelane_b32 v40, s65, 17
; CHECK-NEXT:  .LBB0_1: ; =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    v_readfirstlane_b32 s16, v0
; CHECK-NEXT:    v_cmp_eq_u32_e32 vcc, s16, v0
; CHECK-NEXT:    s_and_saveexec_b64 s[64:65], vcc
; CHECK-NEXT:    s_getpc_b64 s[18:19]
; CHECK-NEXT:    s_add_u32 s18, s18, void_func_i32_inreg@rel32@lo+4
; CHECK-NEXT:    s_addc_u32 s19, s19, void_func_i32_inreg@rel32@hi+12
; CHECK-NEXT:    s_mov_b64 s[4:5], s[48:49]
; CHECK-NEXT:    s_mov_b64 s[6:7], s[38:39]
; CHECK-NEXT:    s_mov_b64 s[8:9], s[36:37]
; CHECK-NEXT:    s_mov_b64 s[10:11], s[34:35]
; CHECK-NEXT:    s_mov_b32 s12, s53
; CHECK-NEXT:    s_mov_b32 s13, s52
; CHECK-NEXT:    s_mov_b32 s14, s51
; CHECK-NEXT:    s_mov_b32 s15, s50
; CHECK-NEXT:    s_mov_b32 s0, s16
; CHECK-NEXT:    s_swappc_b64 s[30:31], s[18:19]
; CHECK-NEXT:    ; implicit-def: $vgpr0
; CHECK-NEXT:    ; implicit-def: $vgpr31
; CHECK-NEXT:    s_xor_b64 exec, exec, s[64:65]
; CHECK-NEXT:    s_cbranch_execnz .LBB0_1
; CHECK-NEXT:  ; %bb.2:
; CHECK-NEXT:    s_mov_b64 exec, s[54:55]
; CHECK-NEXT:    v_readlane_b32 s65, v40, 17
; CHECK-NEXT:    v_readlane_b32 s64, v40, 16
; CHECK-NEXT:    v_readlane_b32 s55, v40, 15
; CHECK-NEXT:    v_readlane_b32 s54, v40, 14
; CHECK-NEXT:    v_readlane_b32 s53, v40, 13
; CHECK-NEXT:    v_readlane_b32 s52, v40, 12
; CHECK-NEXT:    v_readlane_b32 s51, v40, 11
; CHECK-NEXT:    v_readlane_b32 s50, v40, 10
; CHECK-NEXT:    v_readlane_b32 s49, v40, 9
; CHECK-NEXT:    v_readlane_b32 s48, v40, 8
; CHECK-NEXT:    v_readlane_b32 s39, v40, 7
; CHECK-NEXT:    v_readlane_b32 s38, v40, 6
; CHECK-NEXT:    v_readlane_b32 s37, v40, 5
; CHECK-NEXT:    v_readlane_b32 s36, v40, 4
; CHECK-NEXT:    v_readlane_b32 s35, v40, 3
; CHECK-NEXT:    v_readlane_b32 s34, v40, 2
; CHECK-NEXT:    v_readlane_b32 s31, v40, 1
; CHECK-NEXT:    v_readlane_b32 s30, v40, 0
; CHECK-NEXT:    s_mov_b32 s32, s33
; CHECK-NEXT:    v_readlane_b32 s4, v40, 18
; CHECK-NEXT:    s_or_saveexec_b64 s[6:7], -1
; CHECK-NEXT:    buffer_load_dword v40, off, s[0:3], s33 ; 4-byte Folded Reload
; CHECK-NEXT:    s_mov_b64 exec, s[6:7]
; CHECK-NEXT:    s_mov_b32 s33, s4
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
  tail call void @void_func_i32_inreg(i32 inreg %vgpr)
  ret void
}

@constant = external hidden addrspace(4) constant ptr

define void @indirect_tail_call_i32_inreg_divergent(i32 %vgpr) {
; CHECK-LABEL: indirect_tail_call_i32_inreg_divergent:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_mov_b32 s16, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_or_saveexec_b64 s[18:19], -1
; CHECK-NEXT:    buffer_store_dword v40, off, s[0:3], s33 ; 4-byte Folded Spill
; CHECK-NEXT:    s_mov_b64 exec, s[18:19]
; CHECK-NEXT:    v_writelane_b32 v40, s16, 20
; CHECK-NEXT:    v_writelane_b32 v40, s30, 0
; CHECK-NEXT:    v_writelane_b32 v40, s31, 1
; CHECK-NEXT:    v_writelane_b32 v40, s34, 2
; CHECK-NEXT:    v_writelane_b32 v40, s35, 3
; CHECK-NEXT:    v_writelane_b32 v40, s36, 4
; CHECK-NEXT:    v_writelane_b32 v40, s37, 5
; CHECK-NEXT:    v_writelane_b32 v40, s38, 6
; CHECK-NEXT:    v_writelane_b32 v40, s39, 7
; CHECK-NEXT:    v_writelane_b32 v40, s48, 8
; CHECK-NEXT:    v_writelane_b32 v40, s49, 9
; CHECK-NEXT:    v_writelane_b32 v40, s50, 10
; CHECK-NEXT:    v_writelane_b32 v40, s51, 11
; CHECK-NEXT:    v_writelane_b32 v40, s52, 12
; CHECK-NEXT:    v_writelane_b32 v40, s53, 13
; CHECK-NEXT:    v_writelane_b32 v40, s54, 14
; CHECK-NEXT:    s_addk_i32 s32, 0x400
; CHECK-NEXT:    v_writelane_b32 v40, s55, 15
; CHECK-NEXT:    v_writelane_b32 v40, s64, 16
; CHECK-NEXT:    s_mov_b64 s[48:49], s[4:5]
; CHECK-NEXT:    s_getpc_b64 s[4:5]
; CHECK-NEXT:    s_add_u32 s4, s4, constant@rel32@lo+4
; CHECK-NEXT:    s_addc_u32 s5, s5, constant@rel32@hi+12
; CHECK-NEXT:    v_writelane_b32 v40, s65, 17
; CHECK-NEXT:    s_load_dwordx2 s[64:65], s[4:5], 0x0
; CHECK-NEXT:    v_writelane_b32 v40, s66, 18
; CHECK-NEXT:    s_mov_b32 s50, s15
; CHECK-NEXT:    s_mov_b32 s51, s14
; CHECK-NEXT:    s_mov_b32 s52, s13
; CHECK-NEXT:    s_mov_b32 s53, s12
; CHECK-NEXT:    s_mov_b64 s[34:35], s[10:11]
; CHECK-NEXT:    s_mov_b64 s[36:37], s[8:9]
; CHECK-NEXT:    s_mov_b64 s[38:39], s[6:7]
; CHECK-NEXT:    s_mov_b64 s[54:55], exec
; CHECK-NEXT:    v_writelane_b32 v40, s67, 19
; CHECK-NEXT:  .LBB1_1: ; =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    v_readfirstlane_b32 s16, v0
; CHECK-NEXT:    v_cmp_eq_u32_e32 vcc, s16, v0
; CHECK-NEXT:    s_and_saveexec_b64 s[66:67], vcc
; CHECK-NEXT:    s_mov_b64 s[4:5], s[48:49]
; CHECK-NEXT:    s_mov_b64 s[6:7], s[38:39]
; CHECK-NEXT:    s_mov_b64 s[8:9], s[36:37]
; CHECK-NEXT:    s_mov_b64 s[10:11], s[34:35]
; CHECK-NEXT:    s_mov_b32 s12, s53
; CHECK-NEXT:    s_mov_b32 s13, s52
; CHECK-NEXT:    s_mov_b32 s14, s51
; CHECK-NEXT:    s_mov_b32 s15, s50
; CHECK-NEXT:    s_mov_b32 s0, s16
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_swappc_b64 s[30:31], s[64:65]
; CHECK-NEXT:    ; implicit-def: $vgpr0
; CHECK-NEXT:    ; implicit-def: $vgpr31
; CHECK-NEXT:    s_xor_b64 exec, exec, s[66:67]
; CHECK-NEXT:    s_cbranch_execnz .LBB1_1
; CHECK-NEXT:  ; %bb.2:
; CHECK-NEXT:    s_mov_b64 exec, s[54:55]
; CHECK-NEXT:    v_readlane_b32 s67, v40, 19
; CHECK-NEXT:    v_readlane_b32 s66, v40, 18
; CHECK-NEXT:    v_readlane_b32 s65, v40, 17
; CHECK-NEXT:    v_readlane_b32 s64, v40, 16
; CHECK-NEXT:    v_readlane_b32 s55, v40, 15
; CHECK-NEXT:    v_readlane_b32 s54, v40, 14
; CHECK-NEXT:    v_readlane_b32 s53, v40, 13
; CHECK-NEXT:    v_readlane_b32 s52, v40, 12
; CHECK-NEXT:    v_readlane_b32 s51, v40, 11
; CHECK-NEXT:    v_readlane_b32 s50, v40, 10
; CHECK-NEXT:    v_readlane_b32 s49, v40, 9
; CHECK-NEXT:    v_readlane_b32 s48, v40, 8
; CHECK-NEXT:    v_readlane_b32 s39, v40, 7
; CHECK-NEXT:    v_readlane_b32 s38, v40, 6
; CHECK-NEXT:    v_readlane_b32 s37, v40, 5
; CHECK-NEXT:    v_readlane_b32 s36, v40, 4
; CHECK-NEXT:    v_readlane_b32 s35, v40, 3
; CHECK-NEXT:    v_readlane_b32 s34, v40, 2
; CHECK-NEXT:    v_readlane_b32 s31, v40, 1
; CHECK-NEXT:    v_readlane_b32 s30, v40, 0
; CHECK-NEXT:    s_mov_b32 s32, s33
; CHECK-NEXT:    v_readlane_b32 s4, v40, 20
; CHECK-NEXT:    s_or_saveexec_b64 s[6:7], -1
; CHECK-NEXT:    buffer_load_dword v40, off, s[0:3], s33 ; 4-byte Folded Reload
; CHECK-NEXT:    s_mov_b64 exec, s[6:7]
; CHECK-NEXT:    s_mov_b32 s33, s4
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
  %fptr = load ptr, ptr addrspace(4) @constant, align 8
  tail call void %fptr(i32 inreg %vgpr)
  ret void
}

declare void @user(ptr addrspace(5))

define amdgpu_kernel void @v_multiple_frame_indexes_literal_offsets() #0 {
; CHECK-LABEL: v_multiple_frame_indexes_literal_offsets:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    s_add_u32 flat_scratch_lo, s12, s17
; CHECK-NEXT:    s_addc_u32 flat_scratch_hi, s13, 0
; CHECK-NEXT:    s_add_u32 s0, s0, s17
; CHECK-NEXT:    v_mov_b32_e32 v3, 8
; CHECK-NEXT:    v_mov_b32_e32 v4, 0
; CHECK-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; CHECK-NEXT:    v_lshlrev_b32_e32 v2, 20, v2
; CHECK-NEXT:    v_lshlrev_b32_e32 v1, 10, v1
; CHECK-NEXT:    s_addc_u32 s1, s1, 0
; CHECK-NEXT:    s_mov_b32 s33, s16
; CHECK-NEXT:    s_mov_b32 s50, s15
; CHECK-NEXT:    s_mov_b32 s51, s14
; CHECK-NEXT:    s_mov_b64 s[34:35], s[10:11]
; CHECK-NEXT:    s_mov_b64 s[36:37], s[8:9]
; CHECK-NEXT:    s_mov_b64 s[38:39], s[6:7]
; CHECK-NEXT:    s_mov_b64 s[48:49], s[4:5]
; CHECK-NEXT:    v_cndmask_b32_e32 v3, v3, v4, vcc
; CHECK-NEXT:    v_or3_b32 v31, v0, v1, v2
; CHECK-NEXT:    s_movk_i32 s32, 0x400
; CHECK-NEXT:    s_mov_b64 s[4:5], exec
; CHECK-NEXT:  .LBB2_1: ; =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    v_readfirstlane_b32 s15, v3
; CHECK-NEXT:    v_cmp_eq_u32_e32 vcc, s15, v3
; CHECK-NEXT:    s_and_saveexec_b64 s[52:53], vcc
; CHECK-NEXT:    s_getpc_b64 s[4:5]
; CHECK-NEXT:    s_add_u32 s4, s4, user@gotpcrel32@lo+4
; CHECK-NEXT:    s_addc_u32 s5, s5, user@gotpcrel32@hi+12
; CHECK-NEXT:    s_load_dwordx2 s[16:17], s[4:5], 0x0
; CHECK-NEXT:    s_mov_b64 s[4:5], s[48:49]
; CHECK-NEXT:    s_mov_b64 s[6:7], s[38:39]
; CHECK-NEXT:    s_mov_b64 s[8:9], s[36:37]
; CHECK-NEXT:    s_mov_b64 s[10:11], s[34:35]
; CHECK-NEXT:    s_mov_b32 s12, s51
; CHECK-NEXT:    s_mov_b32 s13, s50
; CHECK-NEXT:    s_mov_b32 s14, s33
; CHECK-NEXT:    s_mov_b32 s0, s15
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_swappc_b64 s[30:31], s[16:17]
; CHECK-NEXT:    ; implicit-def: $vgpr3
; CHECK-NEXT:    ; implicit-def: $vgpr31
; CHECK-NEXT:    s_xor_b64 exec, exec, s[52:53]
; CHECK-NEXT:    s_cbranch_execnz .LBB2_1
; CHECK-NEXT:  ; %bb.2:
; CHECK-NEXT:    s_endpgm
  %vgpr = call i32 @llvm.amdgcn.workitem.id.x()
  %alloca0 = alloca [2 x i32], align 8, addrspace(5)
  %alloca1 = alloca i32, align 4, addrspace(5)
  %cmp = icmp eq i32 %vgpr, 0
  %select = select i1 %cmp, ptr addrspace(5) %alloca0, ptr addrspace(5) %alloca1
  call void @user(ptr addrspace(5) inreg %select)
  ret void
}

declare noundef range(i32 0, 1024) i32 @llvm.amdgcn.workitem.id.x() #1

attributes #0 = { nounwind }
attributes #1 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
